{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e967b0",
   "metadata": {},
   "source": [
    "### Importing Various Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376dff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014bc1d8",
   "metadata": {},
   "source": [
    "### Reading CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df988ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'utf-8' codec can't decode byte 0xe4 in position 343: invalid continuation byte. Hence for the change in encoding.\n",
    "\n",
    "carriers = pd.read_csv(\"carriers.csv\")\n",
    "plane_data = pd.read_csv(\"plane-data.csv\")\n",
    "airports = pd.read_csv(\"airports.csv\")\n",
    "year_2000 = pd.read_csv(\"2000.csv\")\n",
    "year_2001 = pd.read_csv(\"2001.csv\", encoding = 'windows-1251')\n",
    "year_2002 = pd.read_csv(\"2002.csv\", encoding = 'windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099229fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5683047, 29)\n",
      "(5967780, 29)\n",
      "(5271359, 29)\n"
     ]
    }
   ],
   "source": [
    "# taking a look at the number of rows and columns for each year\n",
    "\n",
    "print(year_2000.shape)\n",
    "print(year_2001.shape)\n",
    "print(year_2002.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486184f",
   "metadata": {},
   "source": [
    "### Concatenating the yearly data sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7bbfa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([year_2000, year_2001, year_2002], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out the total number of rows and columns\n",
    "print(df_combined.shape)\n",
    "\n",
    "# checking for number of null vales in the data set\n",
    "print(df_combined.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not correct as we do not want potential data loss\n",
    "# plane_data = plane_data.dropna()\n",
    "# plane_data = plane_data.drop(plane_data[plane_data.year == \"None\"].index)\n",
    "plane_data = plane_data.drop(plane_data[plane_data.year >= \"2002\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd142b",
   "metadata": {},
   "source": [
    "### Changing to date format for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af83fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane_data[\"issue_date\"] = pd.to_datetime((plane_data[\"issue_date\"]), format=\"%m/%d/%Y\")\n",
    "df_combined[\"issue_date\"] = pd.to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e3c7f",
   "metadata": {},
   "source": [
    "### Removing issue dates before 01 Jan 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a319ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_data = plane_data[~(plane_data[\"issue_date\"] > \"2002-12-31\")]\n",
    "plane_data[\"year\"] = pd.to_numeric(plane_data[\"year\"])\n",
    "plane_data = plane_data.rename(columns={\"year\": \"year_built\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad01f0",
   "metadata": {},
   "source": [
    "### Re-indexing plane_data, renaming columns to inner join plane_data and carriers into df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "plane_data = plane_data.rename(columns={\"tailnum\": \"TailNum\"})\n",
    "carriers = carriers.rename(columns={\"Code\": \"UniqueCarrier\"})\n",
    "\n",
    "df_combined = pd.merge(df_combined, plane_data, on = \"TailNum\")\n",
    "df_combined = pd.merge(df_combined, carriers, on = \"UniqueCarrier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cadef7",
   "metadata": {},
   "source": [
    "# Q1: When is the best time of day, day of the week, and time of year to fly to minimise delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899b953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a new data frame, df_best\n",
    "df_best = df_combined[[\"Year\", \"Month\", \"DayofMonth\", \"DayOfWeek\", \"DepTime\", \"ArrTime\", \"ArrDelay\", \"DepDelay\"]].copy()\n",
    "df_best = df_best.dropna()\n",
    "\n",
    "df_best[\"DepTime\"] = df_best[\"DepTime\"].astype(int)\n",
    "df_best[\"ArrTime\"] = df_best[\"ArrTime\"].astype(int)\n",
    "df_best[\"DepTime\"] = df_best[\"DepTime\"].astype(str).str.zfill(4)\n",
    "df_best[\"ArrTime\"] = df_best[\"ArrTime\"].astype(str).str.zfill(4)\n",
    "df_best[\"DepTime\"] = df_best[\"DepTime\"].astype(str).str.ljust(5, \"0\")\n",
    "df_best[\"ArrTime\"] = df_best[\"ArrTime\"].astype(str).str.ljust(5, \"0\")\n",
    "\n",
    "#Changing DepTime and ArrTime to time format\n",
    "df_best[\"DepTime\"] = pd.to_datetime(df_best[\"DepTime\"], format = \"%H%M%S\")\n",
    "df_best[\"ArrTime\"] = pd.to_datetime(df_best[\"ArrTime\"], format = \"%H%M%S\")\n",
    "\n",
    "#Get day name from day of week\n",
    "days = {1:\"Monday\", 2:\"Tuesday\", 3:\"Wednesday\", 4:\"Thursday\", 5:\"Friday\", 6:\"Saturday\", 7:\"Sunday\"}\n",
    "df_best[\"DayOfWeek\"] = df_best[\"DayOfWeek\"].map(days)\n",
    "\n",
    "#Create new column DelayStatus, TotalDelay, Time Classification and Season\n",
    "df_best[\"DelayStatus\"] = \"\"\n",
    "df_best.insert(4, \"Season\", \"\")\n",
    "df_best.insert(4, \"TimeClass\", \"\")\n",
    "\n",
    "#Factoring in the 15 min grace period, assuming that it is already taken into account in the data\n",
    "conditions = [(df_best[\"DepDelay\"].ge(15)), (df_best[\"DepDelay\"].eq(0)), (df_best[\"DepDelay\"].lt(15)),]\n",
    "delayStatus = [\"Delayed\", \"On Time\", \"Early\"]\n",
    "df_best[\"DelayStatus\"] = np.select(conditions, delayStatus)\n",
    "\n",
    "#Creating column for seasons\n",
    "seasons = {1: \"Winter\", 2:\"Winter\", 3:\"Spring\", 4:\"Spring\", 5:\"Spring\", 6:\"Summer\", 7:\"Summer\", 8:\"Summer\", 9:\"Autumn\", 10:\"Autumn\", 11:\"Autumn\", 12:\"Winter\"}\n",
    "df_best[\"Season\"]  = df_best[\"Month\"].apply(lambda x: seasons[x])\n",
    "\n",
    "#Get time classification\n",
    "def timeClass(x):\n",
    "    if (x >= 6) & (x < 12):\n",
    "        TimeClass = \"Morning\"\n",
    "    elif (x >= 12) & (x < 17):\n",
    "        TimeClass = \"Afternoon\"\n",
    "    elif (x >= 17) & (x < 20):\n",
    "        TimeClass = \"Evening\"\n",
    "    else:\n",
    "        TimeClass = \"Night\"\n",
    "    return TimeClass\n",
    "\n",
    "df_best[\"TimeClass\"] = df_best.DepTime.dt.hour.map(timeClass)\n",
    "df_best[\"DepTime\"] = pd.to_datetime(df_best[\"DepTime\"], format = \"%H%M%S\").dt.strftime(\"%H:%M\")\n",
    "df_best[\"ArrTime\"] = pd.to_datetime(df_best[\"ArrTime\"], format = \"%H%M%S\").dt.strftime(\"%H:%M\")\n",
    "\n",
    "#Plots using matplotlib and seaborn\n",
    "ax = sns.countplot(x = \"DelayStatus\", hue_order = [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"], hue = \"TimeClass\", data = df_best, palette = \"Set2\")\n",
    "ax.set_title(\"Delay Status by Time of Day\")\n",
    "plt.ticklabel_format(style = \"plain\", axis = \"y\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "for container in ax.containers: \n",
    "   ax.bar_label(container, fmt = \"%d\")\n",
    "plt.show()\n",
    "\n",
    "ax = sns.countplot(x = \"DelayStatus\", hue_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], hue = \"DayOfWeek\", data = df_best, palette = \"Set2\")\n",
    "ax.set_title(\"Delay Status by Day Of Week\")\n",
    "plt.ticklabel_format(style = \"plain\", axis = \"y\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 10)\n",
    "for container in ax.containers: \n",
    "   ax.bar_label(container, fmt = \"%d\")\n",
    "plt.show()\n",
    "\n",
    "ax = sns.countplot(x = \"DelayStatus\", hue_order = [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"], hue = \"Season\", data = df_best, palette = \"Set2\")\n",
    "ax.set_title(\"Delay Status by Season\")\n",
    "plt.ticklabel_format(style = \"plain\", axis = \"y\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "for container in ax.containers: \n",
    "   ax.bar_label(container, fmt = \"%d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fee950",
   "metadata": {},
   "source": [
    "# Q2: Do older planes suffer more delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cee75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating new column, DelayStatus\n",
    "df_airplaneAge = df_combined[[\"Year\", \"DepDelay\", \"year_built\"]].copy()\n",
    "df_airplaneAge.insert(2, \"DelayStatus\", \"\")\n",
    "\n",
    "#Referencing from Q1:\n",
    "conditions2 = [(df_airplaneAge[\"DepDelay\"].ge(15)), (df_airplaneAge[\"DepDelay\"].eq(0)), (df_airplaneAge[\"DepDelay\"].lt(15)),]\n",
    "delayStatus2 = [\"Delayed\", \"On Time\", \"Early\"]\n",
    "df_airplaneAge[\"DelayStatus\"] = np.select(conditions2, delayStatus2)\n",
    "df_airplaneAge = df_airplaneAge.dropna()\n",
    "\n",
    "#Creating new column, Plane_Age and finding the age of plane\n",
    "df_airplaneAge[\"Plane_Age\"] = df_airplaneAge[\"Year\"] - df_airplaneAge[\"year_built\"]\n",
    "df_airplaneAge[\"Plane_Age_Range\"] = \"\"\n",
    "df_airplaneAge.loc[df_airplaneAge[\"Plane_Age\"].between(0,10), \"Plane_Age_Range\"] = \"0-10\"\n",
    "df_airplaneAge.loc[df_airplaneAge[\"Plane_Age\"].between(11,20), \"Plane_Age_Range\"] = \"11-20\"\n",
    "df_airplaneAge.loc[df_airplaneAge[\"Plane_Age\"] > 20, \"Plane_Age_Range\"] = \"20+\"\n",
    "\n",
    "#Plot countplot\n",
    "ax2 = sns.countplot(x = \"Plane_Age_Range\", hue = \"DelayStatus\", order = [\"0-10\", \"11-20\", \"20+\"], data = df_airplaneAge, palette = \"Set2\")\n",
    "ax2.set_title(\"Plane Age against Delay Status\")\n",
    "plt.ticklabel_format(style = \"plain\", axis = \"y\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "for container in ax2.containers: \n",
    "   ax2.bar_label(container, fmt = \"%d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276dfa8e",
   "metadata": {},
   "source": [
    "# Q3: How does the number of people flying between different locations change over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edefdf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_people = df_combined[[\"Year\", \"Month\", \"Origin\", \"Dest\"]].copy()\n",
    "df_people = df_people.rename(columns={\"airport\": \"OriAirport\"})\n",
    "airports = airports.rename(columns={\"iata\": \"Origin\"})\n",
    "df_people = pd.merge(df_people, airports, on = \"Origin\")\n",
    "months = {1: \"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"Jun\", 7:\"Jul\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"}\n",
    "df_people[\"Month\"]  = df_people[\"Month\"].apply(lambda x: months[x])\n",
    "\n",
    "#Count the number of flights from each Origin\n",
    "flight_count = df_people[[\"Origin\"]].copy()\n",
    "flight_count.groupby(\"Origin\").size()\n",
    "\n",
    "#Choose ATL(Alanta) as the origin, since it has the highest flight count, and filtering the other Origins out\n",
    "df_people = df_people[df_people.Origin == \"ATL\"]\n",
    "\n",
    "#Count the number of flights from ATL(Atlanta) to each Destination, take the top 3 destinations\n",
    "dest_count = df_people[[\"Dest\"]].copy()\n",
    "dest_count.groupby(\"Dest\").size()\n",
    "\n",
    "\n",
    "#Filter out the other Origins except EWR, LGA and ORD\n",
    "remove_dest = [\"EWR\", \"LGA\", \"ORD\"]\n",
    "df_people = df_people[df_people.Dest.isin(remove_dest)]\n",
    "\n",
    "#Plot countplot\n",
    "ax3 = sns.countplot(x = \"Month\", hue = \"Dest\", order = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], data = df_people, palette = \"Set2\")\n",
    "ax3.set_title(\"Number of Flights per month from ATL\")\n",
    "plt.ticklabel_format(style = \"plain\", axis = \"y\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "for container in ax3.containers: \n",
    "   ax3.bar_label(container, fmt = \"%d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47a570",
   "metadata": {},
   "source": [
    "# Q4: Can you detect cascading failures as delays in one airport create delays in others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0020fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cascading_dest = df_combined[[\"Year\", \"Month\", \"DayofMonth\", \"FlightNum\", \"TailNum\", \"CRSDepTime\", \"DepTime\", \"DepDelay\", \"CRSArrTime\", \"ArrTime\", \"ArrDelay\", \"Origin\", \"Dest\"]].copy()\n",
    "df_cascading_dest = df_cascading_dest[df_cascading_dest.DepDelay >= 15]\n",
    "df_cascading_dest = df_cascading_dest[df_cascading_dest.ArrDelay > 0]\n",
    "\n",
    "#Count the number of flights to each Destination(ATL)\n",
    "cascading_dest_count = df_cascading_dest[[\"Dest\"]].copy()\n",
    "cascading_dest_count.groupby(\"Dest\").size()\n",
    "\n",
    "#Choose ATL(Alanta) as the destination, since it has the highest flight delay count, and filtering the other Dest out\n",
    "df_cascading_dest = df_cascading_dest[df_cascading_dest.Dest == \"ATL\"]\n",
    "\n",
    "##Create new data frame, df_cascading_origin\n",
    "df_cascading_origin = df_combined[[\"Year\", \"Month\", \"DayofMonth\", \"FlightNum\", \"TailNum\", \"CRSDepTime\", \"DepTime\", \"DepDelay\", \"CRSArrTime\", \"ArrTime\", \"ArrDelay\", \"Origin\", \"Dest\"]].copy()\n",
    "df_cascading_origin = df_cascading_origin[df_cascading_origin.DepDelay >= 15]\n",
    "df_cascading_origin = df_cascading_origin[df_cascading_origin.ArrDelay > 0]\n",
    "\n",
    "#Choose ATL(Alanta) as the origin, since it has the highest flight delay count, and filtering the other Origin out\n",
    "df_cascading_origin = df_cascading_origin[df_cascading_origin.Origin == \"ATL\"]\n",
    "\n",
    "#Full join the 2 tables\n",
    "cascading_main = pd.merge(df_cascading_dest, df_cascading_origin, how = \"outer\")\n",
    "\n",
    "#Changing from numeric to time format\n",
    "cascading_main[\"DepTime\"] = cascading_main[\"DepTime\"].astype(int)\n",
    "cascading_main[\"ArrTime\"] = cascading_main[\"ArrTime\"].astype(int)\n",
    "cascading_main[\"CRSDepTime\"] = cascading_main[\"CRSDepTime\"].astype(int)\n",
    "cascading_main[\"CRSArrTime\"] = cascading_main[\"CRSArrTime\"].astype(int)\n",
    "\n",
    "cascading_main[\"DepTime\"] = cascading_main[\"DepTime\"].astype(str).str.zfill(4)\n",
    "cascading_main[\"ArrTime\"] = cascading_main[\"ArrTime\"].astype(str).str.zfill(4)\n",
    "cascading_main[\"CRSDepTime\"] = cascading_main[\"CRSDepTime\"].astype(str).str.zfill(4)\n",
    "cascading_main[\"CRSArrTime\"] = cascading_main[\"CRSArrTime\"].astype(str).str.zfill(4)\n",
    "\n",
    "cascading_main[\"DepTime\"] = cascading_main[\"DepTime\"].astype(str).str.ljust(5, \"0\")\n",
    "cascading_main[\"ArrTime\"] = cascading_main[\"ArrTime\"].astype(str).str.ljust(5, \"0\")\n",
    "cascading_main[\"CRSDepTime\"] = cascading_main[\"CRSDepTime\"].astype(str).str.ljust(5, \"0\")\n",
    "cascading_main[\"CRSArrTime\"] = cascading_main[\"CRSArrTime\"].astype(str).str.ljust(5, \"0\")\n",
    "print(cascading_main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
